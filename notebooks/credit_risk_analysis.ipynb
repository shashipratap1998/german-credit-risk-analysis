{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German Credit Risk Analysis and Predictive Modeling using Machine Learning Techniques\n",
    "\n",
    "This notebook implements a machine learning pipeline to predict credit risk using the **German Credit Dataset**. The goal is to classify customers as either \"good\" or \"bad\" credit risks based on various features such as age, job status, loan amount, and credit history.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents:\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Loading the Dataset](#Loading-the-Dataset)\n",
    "3. [Exploratory Data Analysis (EDA)](#Exploratory-Data-Analysis)\n",
    "4. [Data Preprocessing](#Data-Preprocessing)\n",
    "5. [Model Training](#Model-Training)\n",
    "6. [Model Evaluation](#Model-Evaluation)\n",
    "7. [Making Predictions on New Data](#Making-Predictions-on-New-Data)\n",
    "8. [Conclusion](#Conclusion)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introduction <a id=\"Introduction\"></a>\n",
    "\n",
    "In this notebook, we will:\n",
    "- Load the **German Credit Dataset**.\n",
    "- Preprocess the data by encoding categorical variables and scaling numerical features.\n",
    "- Train three machine learning models: **Logistic Regression**, **Random Forest**, and **Gradient Boosting**.\n",
    "- Evaluate the models using accuracy and F1 score.\n",
    "- Make predictions on new customer data.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Loading the Dataset <a id=\"Loading-the-Dataset\"></a>\n",
    "\n",
    "We will start by loading the dataset from a `.data` file and assigning appropriate column names based on the dataset documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (1000, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status_of_existing_checking_account</th>\n",
       "      <th>Duration_in_month</th>\n",
       "      <th>Credit_history</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Credit_amount</th>\n",
       "      <th>Savings_account_bonds</th>\n",
       "      <th>Present_employment_since</th>\n",
       "      <th>Installment_rate_in_percentage_of_disposable_income</th>\n",
       "      <th>Personal_status_and_sex</th>\n",
       "      <th>Other_debtors_guarantors</th>\n",
       "      <th>...</th>\n",
       "      <th>Property</th>\n",
       "      <th>Age_in_years</th>\n",
       "      <th>Other_installment_plans</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Number_of_existing_credits_at_this_bank</th>\n",
       "      <th>Job</th>\n",
       "      <th>Number_of_people_being_liable_to_provide_maintenance_for</th>\n",
       "      <th>Telephone</th>\n",
       "      <th>Foreign_worker</th>\n",
       "      <th>Credit_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A11</td>\n",
       "      <td>6</td>\n",
       "      <td>A34</td>\n",
       "      <td>A43</td>\n",
       "      <td>1169</td>\n",
       "      <td>A65</td>\n",
       "      <td>A75</td>\n",
       "      <td>4</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>67</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A12</td>\n",
       "      <td>48</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>5951</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>2</td>\n",
       "      <td>A92</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>22</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14</td>\n",
       "      <td>12</td>\n",
       "      <td>A34</td>\n",
       "      <td>A46</td>\n",
       "      <td>2096</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>49</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A172</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A11</td>\n",
       "      <td>42</td>\n",
       "      <td>A32</td>\n",
       "      <td>A42</td>\n",
       "      <td>7882</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>A103</td>\n",
       "      <td>...</td>\n",
       "      <td>A122</td>\n",
       "      <td>45</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A11</td>\n",
       "      <td>24</td>\n",
       "      <td>A33</td>\n",
       "      <td>A40</td>\n",
       "      <td>4870</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>3</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A124</td>\n",
       "      <td>53</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Status_of_existing_checking_account  Duration_in_month Credit_history  \\\n",
       "0                                 A11                  6            A34   \n",
       "1                                 A12                 48            A32   \n",
       "2                                 A14                 12            A34   \n",
       "3                                 A11                 42            A32   \n",
       "4                                 A11                 24            A33   \n",
       "\n",
       "  Purpose  Credit_amount Savings_account_bonds Present_employment_since  \\\n",
       "0     A43           1169                   A65                      A75   \n",
       "1     A43           5951                   A61                      A73   \n",
       "2     A46           2096                   A61                      A74   \n",
       "3     A42           7882                   A61                      A74   \n",
       "4     A40           4870                   A61                      A73   \n",
       "\n",
       "   Installment_rate_in_percentage_of_disposable_income  \\\n",
       "0                                                  4     \n",
       "1                                                  2     \n",
       "2                                                  2     \n",
       "3                                                  2     \n",
       "4                                                  3     \n",
       "\n",
       "  Personal_status_and_sex Other_debtors_guarantors  ...  Property  \\\n",
       "0                     A93                     A101  ...      A121   \n",
       "1                     A92                     A101  ...      A121   \n",
       "2                     A93                     A101  ...      A121   \n",
       "3                     A93                     A103  ...      A122   \n",
       "4                     A93                     A101  ...      A124   \n",
       "\n",
       "  Age_in_years  Other_installment_plans Housing  \\\n",
       "0           67                     A143    A152   \n",
       "1           22                     A143    A152   \n",
       "2           49                     A143    A152   \n",
       "3           45                     A143    A153   \n",
       "4           53                     A143    A153   \n",
       "\n",
       "  Number_of_existing_credits_at_this_bank   Job  \\\n",
       "0                                       2  A173   \n",
       "1                                       1  A173   \n",
       "2                                       1  A172   \n",
       "3                                       1  A173   \n",
       "4                                       2  A173   \n",
       "\n",
       "  Number_of_people_being_liable_to_provide_maintenance_for  Telephone  \\\n",
       "0                                                  1             A192   \n",
       "1                                                  1             A191   \n",
       "2                                                  2             A191   \n",
       "3                                                  2             A191   \n",
       "4                                                  2             A191   \n",
       "\n",
       "  Foreign_worker Credit_risk  \n",
       "0           A201           1  \n",
       "1           A201           2  \n",
       "2           A201           1  \n",
       "3           A201           1  \n",
       "4           A201           2  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define column names based on german.doc (documentation)\n",
    "columns = [\n",
    "    'Status_of_existing_checking_account', 'Duration_in_month', 'Credit_history',\n",
    "    'Purpose', 'Credit_amount', 'Savings_account_bonds', 'Present_employment_since',\n",
    "    'Installment_rate_in_percentage_of_disposable_income', 'Personal_status_and_sex',\n",
    "    'Other_debtors_guarantors', 'Present_residence_since', 'Property',\n",
    "    'Age_in_years', 'Other_installment_plans', 'Housing',\n",
    "    'Number_of_existing_credits_at_this_bank', 'Job',\n",
    "    'Number_of_people_being_liable_to_provide_maintenance_for',\n",
    "    'Telephone', 'Foreign_worker', 'Credit_risk'\n",
    "]\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"C:/Users/shash/OneDrive/Desktop/Repos/german-credit-risk-analysis/data/german.data\"\n",
    "df = pd.read_csv(file_path, sep=' ', header=None, names=columns)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "- The dataset contains 1000 rows and 21 columns.\n",
    "- Each row represents a customer applying for credit, with features such as `Credit_amount`, `Duration_in_month`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA) <a id=\"Exploratory-Data-Analysis\"></a>\n",
    "\n",
    "Before preprocessing, let's explore the dataset to understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration_in_month</th>\n",
       "      <th>Credit_amount</th>\n",
       "      <th>Installment_rate_in_percentage_of_disposable_income</th>\n",
       "      <th>Present_residence_since</th>\n",
       "      <th>Age_in_years</th>\n",
       "      <th>Number_of_existing_credits_at_this_bank</th>\n",
       "      <th>Number_of_people_being_liable_to_provide_maintenance_for</th>\n",
       "      <th>Credit_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.903000</td>\n",
       "      <td>3271.258000</td>\n",
       "      <td>2.973000</td>\n",
       "      <td>2.845000</td>\n",
       "      <td>35.546000</td>\n",
       "      <td>1.407000</td>\n",
       "      <td>1.155000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.058814</td>\n",
       "      <td>2822.736876</td>\n",
       "      <td>1.118715</td>\n",
       "      <td>1.103718</td>\n",
       "      <td>11.375469</td>\n",
       "      <td>0.577654</td>\n",
       "      <td>0.362086</td>\n",
       "      <td>0.458487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>1365.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>2319.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>3972.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>18424.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Duration_in_month  Credit_amount  \\\n",
       "count        1000.000000    1000.000000   \n",
       "mean           20.903000    3271.258000   \n",
       "std            12.058814    2822.736876   \n",
       "min             4.000000     250.000000   \n",
       "25%            12.000000    1365.500000   \n",
       "50%            18.000000    2319.500000   \n",
       "75%            24.000000    3972.250000   \n",
       "max            72.000000   18424.000000   \n",
       "\n",
       "       Installment_rate_in_percentage_of_disposable_income  \\\n",
       "count                                        1000.000000     \n",
       "mean                                            2.973000     \n",
       "std                                             1.118715     \n",
       "min                                             1.000000     \n",
       "25%                                             2.000000     \n",
       "50%                                             3.000000     \n",
       "75%                                             4.000000     \n",
       "max                                             4.000000     \n",
       "\n",
       "       Present_residence_since  Age_in_years  \\\n",
       "count              1000.000000   1000.000000   \n",
       "mean                  2.845000     35.546000   \n",
       "std                   1.103718     11.375469   \n",
       "min                   1.000000     19.000000   \n",
       "25%                   2.000000     27.000000   \n",
       "50%                   3.000000     33.000000   \n",
       "75%                   4.000000     42.000000   \n",
       "max                   4.000000     75.000000   \n",
       "\n",
       "       Number_of_existing_credits_at_this_bank  \\\n",
       "count                              1000.000000   \n",
       "mean                                  1.407000   \n",
       "std                                   0.577654   \n",
       "min                                   1.000000   \n",
       "25%                                   1.000000   \n",
       "50%                                   1.000000   \n",
       "75%                                   2.000000   \n",
       "max                                   4.000000   \n",
       "\n",
       "       Number_of_people_being_liable_to_provide_maintenance_for  Credit_risk  \n",
       "count                                        1000.000000         1000.000000  \n",
       "mean                                            1.155000            1.300000  \n",
       "std                                             0.362086            0.458487  \n",
       "min                                             1.000000            1.000000  \n",
       "25%                                             1.000000            1.000000  \n",
       "50%                                             1.000000            1.000000  \n",
       "75%                                             1.000000            2.000000  \n",
       "max                                             2.000000            2.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "# Check data types of each column\n",
    "df.dtypes\n",
    "\n",
    "# Check unique values in categorical columns (e.g., Credit_history)\n",
    "df['Credit_history'].unique()\n",
    "\n",
    "# Summary statistics for numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "- There are no missing values in the dataset.\n",
    "- The dataset contains both categorical and numerical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing <a id=\"Data-Preprocessing\"></a>\n",
    "\n",
    "We will now preprocess the data by:\n",
    "1. Encoding categorical variables using **One-Hot Encoding**.\n",
    "2. Scaling numerical features using **StandardScaler**.\n",
    "3. Balancing classes using **SMOTE** (Synthetic Minority Over-sampling Technique)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (1118, 61)\n",
      "Test Data Shape: (200, 61)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Separate features and target variable ('Credit_risk')\n",
    "X = df.drop('Credit_risk', axis=1)\n",
    "y = df['Credit_risk']\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocessing pipeline for numerical and categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Split data into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply preprocessing pipeline to training and test data\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Apply SMOTE to balance classes in training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_preprocessed, y_train)\n",
    "\n",
    "print(f\"Training Data Shape: {X_train_smote.shape}\")\n",
    "print(f\"Test Data Shape: {X_test_preprocessed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "- We used **One-Hot Encoding** to convert categorical variables into binary columns.\n",
    "- We used **StandardScaler** to scale numerical features.\n",
    "- We applied **SMOTE** to balance the classes in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Train Logistic Regression model\n",
    "log_reg_model = LogisticRegression(max_iter=1000)\n",
    "log_reg_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Train Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "print(\"Models trained successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "We trained three different models on the preprocessed training data:\n",
    "1. Logistic Regression: A linear model for binary classification.\n",
    "2. Random Forest: An ensemble method that builds multiple decision trees.\n",
    "3. Gradient Boosting: An ensemble method that builds trees sequentially to minimize errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Model Evaluation <a id=\"Model-Evaluation\"></a>\n",
    "We will evaluate each model using accuracy and F1 score.\n",
    "python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "print(\"Evaluating Logistic Regression Model:\")\n",
    "evaluate_model(log_reg_model, X_test_preprocessed, y_test)\n",
    "\n",
    "print(\"\\nEvaluating Random Forest Model:\")\n",
    "evaluate_model(rf_model, X_test_preprocessed, y_test)\n",
    "\n",
    "print(\"\\nEvaluating Gradient Boosting Model:\")\n",
    "evaluate_model(gb_model, X_test_preprocessed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training <a id=\"Model-Training\"></a>\n",
    "\n",
    "We will now train three machine learning models:\n",
    "1. Logistic Regression\n",
    "2. Random Forest Classifier\n",
    "3. Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models trained successfully.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Train Logistic Regression model\n",
    "log_reg_model = LogisticRegression(max_iter=1000)\n",
    "log_reg_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Train Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "print(\"Models trained successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "We trained three different models on the preprocessed training data:\n",
    "1. Logistic Regression: A linear model for binary classification.\n",
    "2. Random Forest: An ensemble method that builds multiple decision trees.\n",
    "3. Gradient Boosting: An ensemble method that builds trees sequentially to minimize errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation <a id=\"Model-Evaluation\"></a>\n",
    "\n",
    "We will evaluate each model using accuracy and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression Model:\n",
      "Accuracy: 0.7450\n",
      "F1 Score: 0.8061\n",
      "\n",
      "Evaluating Random Forest Model:\n",
      "Accuracy: 0.8000\n",
      "F1 Score: 0.8649\n",
      "\n",
      "Evaluating Gradient Boosting Model:\n",
      "Accuracy: 0.7800\n",
      "F1 Score: 0.8462\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "print(\"Evaluating Logistic Regression Model:\")\n",
    "evaluate_model(log_reg_model, X_test_preprocessed, y_test)\n",
    "\n",
    "print(\"\\nEvaluating Random Forest Model:\")\n",
    "evaluate_model(rf_model, X_test_preprocessed, y_test)\n",
    "\n",
    "print(\"\\nEvaluating Gradient Boosting Model:\")\n",
    "evaluate_model(gb_model, X_test_preprocessed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "The models are evaluated using two key metrics:\n",
    "1. **Accuracy**: The percentage of correct predictions out of all predictions made.\n",
    "2. **F1 Score**: The harmonic mean of precision and recall (useful when dealing with imbalanced datasets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Making Predictions on New Data <a id=\"Making-Predictions-on-New-Data\"></a>\n",
    "\n",
    "We will now simulate predictions on new customer data using all three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Making Predictions on New Customer Data:\n",
      "Logistic Regression Prediction: [2]\n",
      "Random Forest Prediction: [2]\n",
      "Gradient Boosting Prediction: [2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_prediction(model, new_data):\n",
    "    prediction = model.predict(new_data)\n",
    "    return prediction\n",
    "\n",
    "# Simulate new customer data (replace these values with actual preprocessed values)\n",
    "new_customer_data = np.array([X_test_preprocessed[0]])  # Using an example from test set\n",
    "\n",
    "print(\"\\nMaking Predictions on New Customer Data:\")\n",
    "\n",
    "log_reg_prediction = make_prediction(log_reg_model, new_customer_data)\n",
    "print(f\"Logistic Regression Prediction: {log_reg_prediction}\")\n",
    "\n",
    "rf_prediction = make_prediction(rf_model, new_customer_data)\n",
    "print(f\"Random Forest Prediction: {rf_prediction}\")\n",
    "\n",
    "gb_prediction = make_prediction(gb_model, new_customer_data)\n",
    "print(f\"Gradient Boosting Prediction: {gb_prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "We simulated a new customer's data (using a sample from the test set) and passed it through each of the trained models to get predictions.\n",
    "The output shows whether each model predicts this customer as a good or bad credit risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion <a id=\"Conclusion\"></a>\n",
    "\n",
    "In this project:\n",
    "- We loaded and preprocessed the German Credit Dataset.\n",
    "- We trained three machine learning models (Logistic Regression, Random Forests, Gradient Boosting).\n",
    "- We evaluated their performance using accuracy and F1 score.\n",
    "- We made predictions on new customer data.\n",
    "\n",
    "The best-performing model was **Random Forest**, which achieved an accuracy of 80% and an F1 score of 0.8649.\n",
    "\n",
    "Further improvements could be made by tuning hyperparameters or deploying the model for real-time credit risk prediction.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
